{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/burakozturan/bliss/blob/main/BlISS_Lab08_LLM_Capabilities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "module7-header"
      },
      "source": [
        "# Lab 08: Discovering What LLMs Can Do - 10 Core Capabilities\n",
        "\n",
        "**Duration**: 120 minutes | **Prerequisites**: Lab 07 (Transformers) | **Cost**: $0\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "By the end of this module, you'll be able to:\n",
        "- Use 10 fundamental LLM capabilities through Hugging Face\n",
        "- Select appropriate models for different tasks\n",
        "- Combine capabilities for research applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quick-reference"
      },
      "source": [
        "## üìã Quick Reference Card\n",
        "Keep this open while working!\n",
        "\n",
        "| ID | Capability | Task | Recommended Model | Memory | Example Use |\n",
        "|---|---|---|---|---|---|\n",
        "| A1 | Text Classification | Categorize text | `distilbert-base-uncased` | ~250MB | Sort papers by topic |\n",
        "| A2 | NER | Find entities | `dslim/bert-base-NER` | ~400MB | Extract philosopher names |\n",
        "| A3 | Zero-Shot | Flexible categories | `facebook/bart-large-mnli` | ~1.6GB | Custom classifications |\n",
        "| B1 | Question Answering | Extract info | `distilbert-base-cased-distilled-squad` | ~250MB | Find specific claims |\n",
        "| B2 | Summarization | Condense text | `sshleifer/distilbart-cnn-12-6` | ~1.2GB | Abstract papers |\n",
        "| B3 | Feature Extraction | Text similarity | `sentence-transformers/all-MiniLM-L6-v2` | ~90MB | Find related concepts |\n",
        "| C1 | Text Generation | Create text | `gpt2` | ~500MB | Brainstorm ideas |\n",
        "| C2 | Translation | Convert languages | `Helsinki-NLP/opus-mt-en-de` | ~300MB | Access global philosophy |\n",
        "| C3 | Chat Models | Dialogue | `microsoft/DialoGPT-small` | ~350MB | Interactive exploration |\n",
        "| C4 | Text-to-Image* | Visualize | `runwayml/stable-diffusion-v1-5` | ~4GB | Concept visualization |\n",
        "\n",
        "*Text-to-Image requires significant resources - we'll demonstrate conceptually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1-header"
      },
      "source": [
        "## Part 1: Setup (5 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-cell"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install -q transformers torch sentencepiece sentence-transformers\n",
        "\n",
        "from transformers import pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Hide unnecessary warnings\n",
        "\n",
        "# Check if we have a GPU (Graphics Processing Unit) for faster processing\n",
        "import torch\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "if device == 0:\n",
        "    print(\"üöÄ GPU detected! Models will run faster!\")\n",
        "else:\n",
        "    print(\"üíª Using CPU (works fine, just slower)\")\n",
        "    #üí° Tip: In Colab, go to Runtime ‚Üí Change runtime type ‚Üí GPU\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffq5ix0g87OT"
      },
      "source": [
        "### Your First AI Pipeline\n",
        "\n",
        "ü§î **What's a Pipeline?**\n",
        "\n",
        "A pipeline is a program that:\n",
        "1. Takes your text\n",
        "2. Processes it through an AI model\n",
        "3. Gives you useful results\n",
        "\n",
        "Let's create your first one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "category-a-header"
      },
      "source": [
        "## Part 2: Category A - Understanding Text (30 minutes)\n",
        "\n",
        "### A1. Text Classification - Categorizing Ideas\n",
        "\n",
        "üìö **What is Text Classification?**\n",
        "- Classification puts text into categories\n",
        "- Like sorting mail into different folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1-example"
      },
      "outputs": [],
      "source": [
        "# üéØ Your First AI Model - Sentiment Analysis\n",
        "# This model can detect if a text's sentiment is positive or negative\n",
        "\n",
        "# Load classifier\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=device)\n",
        "\n",
        "# Minimal example\n",
        "result = classifier(\"AI can help humanity solve complex problems\")\n",
        "print(f\"Text: 'AI can help humanity solve complex problems'\")\n",
        "print(f\"Result: {result[0]['label']} ({result[0]['score']:.2%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1-exercise-header"
      },
      "source": [
        "#### üéØ Exercise A1: Classify Philosophical Statements\n",
        "**Objective**: Analyze how AI perceives different philosophical claims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1-exercise"
      },
      "outputs": [],
      "source": [
        "statements = [\n",
        "    \"The unexamined life is not worth living\",\n",
        "    \"Knowledge is power\"\n",
        "    # TODO: Add more philosophical statements\n",
        "]\n",
        "\n",
        "# TODO: Classify each statement and count positive vs negative\n",
        "# Expected outcome: A summary showing the distribution of sentiments\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1-hints"
      },
      "source": [
        "<details>\n",
        "<summary>üí° Hint 1</summary>\n",
        "Think about using a loop to process each statement\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>üí° Hint 2</summary>\n",
        "Keep counters for positive and negative classifications\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>üí° Hint 3</summary>\n",
        "Access the label with result[0]['label']\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2-header"
      },
      "source": [
        "### A2. Named Entity Recognition - Finding Important Things\n",
        "\n",
        "üîç **What is NER (Named Entity Recognition)?**\n",
        "- Finds and labels important things in text\n",
        "- People, places, organizations, dates\n",
        "- Like highlighting all the important names in a book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2-example"
      },
      "outputs": [],
      "source": [
        "# Load NER model\n",
        "ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\", device=device)\n",
        "\n",
        "# Minimal example\n",
        "text = \"Plato founded the Academy in Athens\"\n",
        "entities = ner(text)\n",
        "for entity in entities:\n",
        "    print(f\"{entity['word']}: {entity['entity_group']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2-exercise-header"
      },
      "source": [
        "#### üéØ Exercise A2: Build a Philosopher Database\n",
        "**Objective**: Extract all people and places from philosophical texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2-exercise"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"Immanuel Kant was born in K√∂nigsberg in 1724\",\n",
        "    \"Simone de Beauvoir met Jean-Paul Sartre in Paris\",\n",
        "    # TODO: Add 3 more texts about philosophers\n",
        "]\n",
        "\n",
        "# TODO: Extract all PERSON and LOCATION entities\n",
        "# Create a dictionary: {entity_type: [list of unique entities]}\n",
        "# Expected outcome: {'PERSON': [...], 'LOCATION': [...]}\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2-hints"
      },
      "source": [
        "<details>\n",
        "<summary>üí° Hint 1</summary>\n",
        "Process each text with the ner pipeline\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>üí° Hint 2</summary>\n",
        "Check entity['entity_group'] for PER and LOC\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3-header"
      },
      "source": [
        "### A3. Zero-Shot Classification - Flexible Categories\n",
        "\n",
        "üéØ **What is Zero-Shot Classification?**\n",
        "- Classify text into ANY categories you define\n",
        "- No training needed - just describe the categories!\n",
        "- Like having a librarian who can create new sections on demand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3-example"
      },
      "outputs": [],
      "source": [
        "# Load zero-shot classifier\n",
        "zero_shot = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
        "\n",
        "# Minimal example\n",
        "text = \"What is the nature of consciousness?\"\n",
        "categories = [\"ethics\", \"metaphysics\", \"epistemology\"]\n",
        "result = zero_shot(text, candidate_labels=categories)\n",
        "print(f\"Top category: {result['labels'][0]} ({result['scores'][0]:.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "jW0zb1YxqS8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3-exercise-header"
      },
      "source": [
        "#### üéØ Exercise A3: Create Custom Categories\n",
        "**Objective**: Design and test your own classification system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3-exercise"
      },
      "outputs": [],
      "source": [
        "# TODO: Create a classification system for philosophical texts\n",
        "# 1. Define 5-7 categories relevant to your interests\n",
        "# 2. Classify at least 5 different texts\n",
        "# 3. Find which category appears most frequently\n",
        "\n",
        "philosophical_texts = [\n",
        "    # TODO: Add your texts here\n",
        "]\n",
        "\n",
        "my_categories = [\n",
        "    # TODO: Add your categories here\n",
        "]\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3-hints"
      },
      "source": [
        "<details>\n",
        "<summary>üí° Hint 1</summary>\n",
        "Categories could be: time periods, schools of thought, or topics\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>üí° Hint 2</summary>\n",
        "Track results in a dictionary to count frequencies\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "category-a-synthesis-header"
      },
      "source": [
        "### üîß Category A Synthesis\n",
        "**Objective**: Combine classification and NER for comprehensive text analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "category-a-synthesis"
      },
      "outputs": [],
      "source": [
        "def analyze_philosophical_text(text):\n",
        "    \"\"\"Combine multiple understanding capabilities\"\"\"\n",
        "    # TODO: Use all three A-category tools to analyze a text\n",
        "    # Return a dictionary with:\n",
        "    # - sentiment (from A1)\n",
        "    # - entities (from A2)\n",
        "    # - philosophical branch (from A3)\n",
        "    pass\n",
        "\n",
        "# Test your function\n",
        "sample_text = \"Socrates taught Plato in Athens that wisdom comes from knowing one's ignorance\"\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "category-b-header"
      },
      "source": [
        "## Part 3: Category B - Working with Knowledge (30 minutes)\n",
        "\n",
        "### B1. Question Answering - Extract Information\n",
        "\n",
        "‚ùì **What is Question Answering?**\n",
        "- AI finds answers in a given text\n",
        "- Like having a research assistant who reads for you\n",
        "- Useful for: Literature review, finding specific information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1-example"
      },
      "outputs": [],
      "source": [
        "# Load QA model\n",
        "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", device=device)\n",
        "\n",
        "# Minimal example\n",
        "context = \"The Stoics believed that virtue is the only true good.\"\n",
        "question = \"What did the Stoics believe?\"\n",
        "answer = qa_model(question=question, context=context)\n",
        "print(f\"Answer: {answer['answer']} (confidence: {answer['score']:.2%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1-exercise-header"
      },
      "source": [
        "#### üéØ Exercise B1: Philosophical Q&A System\n",
        "**Objective**: Extract key information from a philosophical text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1-exercise"
      },
      "outputs": [],
      "source": [
        "context = \"\"\"\n",
        "[TODO: Paste a paragraph from a philosophical text here -\n",
        "could be from Stanford Encyclopedia, a paper abstract, etc.]\n",
        "\"\"\"\n",
        "\n",
        "questions = [\n",
        "    # TODO: Create 5 questions about your text\n",
        "]\n",
        "\n",
        "# TODO: Get answers for all questions\n",
        "# For each answer, also print the confidence score\n",
        "# Expected outcome: Q&A pairs with confidence levels\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1-hints"
      },
      "source": [
        "<details>\n",
        "<summary>üí° Hint 1</summary>\n",
        "Loop through your questions list\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>üí° Hint 2</summary>\n",
        "Check if confidence is above 50% for reliable answers\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2-header"
      },
      "source": [
        "### B2. Summarization - Condensing Knowledge\n",
        "\n",
        "üìù **What is Summarization?**\n",
        "- Condense long texts while preserving key ideas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2-example"
      },
      "outputs": [],
      "source": [
        "# Load summarizer\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", device=device)\n",
        "\n",
        "# Minimal example\n",
        "long_text = \"\"\"The trolley problem is a thought experiment in ethics about a fictional scenario\n",
        "in which an onlooker has the choice to save 5 people in danger of being hit by a trolley,\n",
        "by diverting the trolley to kill just 1 person. The problem highlights the difference between\n",
        "deontological and consequentialist ethical frameworks.\"\"\"\n",
        "summary = summarizer(long_text, max_length=50, min_length=10)\n",
        "print(summary[0]['summary_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2-exercise-header"
      },
      "source": [
        "#### üéØ Exercise B2: Research Paper Digest\n",
        "**Objective**: Create concise summaries of philosophical arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2-exercise"
      },
      "outputs": [],
      "source": [
        "# TODO: Find and summarize 3 philosophical arguments\n",
        "# Each should be 150-300 words originally\n",
        "# Summarize to 30-50 words each\n",
        "\n",
        "arguments = [\n",
        "    # TODO: Add your philosophical arguments here\n",
        "]\n",
        "\n",
        "# TODO: Create summaries and calculate compression ratios\n",
        "# Expected outcome: Original length ‚Üí Summary length for each\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2-hints"
      },
      "source": [
        "<details>\n",
        "<summary>üí° Hint 1</summary>\n",
        "Use len(text.split()) to count words\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>üí° Hint 2</summary>\n",
        "Compression ratio = original_length / summary_length\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3-header"
      },
      "source": [
        "### B3. Feature Extraction - Understanding Meaning\n",
        "\n",
        "üß† What is Feature Extraction?\n",
        "\n",
        "- Converts text into numbers that capture semantic similarities\n",
        "- Allows us to find similar texts\n",
        "- Like creating a \"fingerprint\" of ideas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3-example"
      },
      "outputs": [],
      "source": [
        "# Load feature extractor\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Minimal example\n",
        "texts = [\"Knowledge is power\", \"Power comes from knowledge\"]\n",
        "embeddings = embedder.encode(texts)\n",
        "similarity = np.dot(embeddings[0], embeddings[1])\n",
        "print(f\"Similarity score: {similarity:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3-exercise-header"
      },
      "source": [
        "#### üéØ Exercise B3: Concept Similarity Explorer\n",
        "**Objective**: Find which philosophical concepts are most related"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3-exercise"
      },
      "outputs": [],
      "source": [
        "concepts = [\n",
        "    \"free will\",\n",
        "    \"determinism\",\n",
        "    \"consciousness\",\n",
        "    \"moral responsibility\",\n",
        "    \"causation\",\n",
        "    # TODO: Add 5 more philosophical concepts\n",
        "]\n",
        "\n",
        "# TODO: Find the most similar pair of concepts\n",
        "# Expected outcome: \"X and Y are most similar (score: 0.XX)\"\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3-hints"
      },
      "source": [
        "<details>\n",
        "<summary>üí° Hint 1</summary>\n",
        "You'll need to compare every pair of concepts\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>üí° Hint 2</summary>\n",
        "Use nested loops or itertools.combinations\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "category-b-synthesis-header"
      },
      "source": [
        "### üîß Category B Synthesis\n",
        "**Objective**: Build a knowledge extraction pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "category-b-synthesis"
      },
      "outputs": [],
      "source": [
        "def extract_knowledge(text):\n",
        "    \"\"\"Extract structured knowledge from philosophical text\"\"\"\n",
        "    # TODO: Combine B-category tools to:\n",
        "    # 1. Summarize the text (B2)\n",
        "    # 2. Generate 3 key questions and answer them (B1)\n",
        "    # 3. Extract key concepts and find their similarities (B3)\n",
        "    pass\n",
        "\n",
        "# Test with a philosophical text\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "category-c-header"
      },
      "source": [
        "## Part 4: Category C - Creating and Connecting (30 minutes)\n",
        "\n",
        "### C1. Text Generation - AI as a Writing Partner\n",
        "\n",
        "‚úçÔ∏è **What is Text Generation?**\n",
        "- AI continues or creates text based on a prompt\n",
        "- Like having a writing assistant that knows many styles\n",
        "- Useful for: Brainstorming, exploring ideas, creating examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1-example"
      },
      "outputs": [],
      "source": [
        "# Load generator\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\", device=device)\n",
        "\n",
        "# Minimal example\n",
        "prompt = \"The meaning of life is\"\n",
        "result = generator(prompt,\n",
        "                   max_length=30,\n",
        "                   num_return_sequences=1,\n",
        "                   temperature=0.8  # Controls randomness (0=predictable, 2=creative)\n",
        ")\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1-exercise-header"
      },
      "source": [
        "#### üéØ Exercise C1: Philosophical Prompt Explorer\n",
        "**Objective**: Explore how AI continues philosophical thoughts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1-exercise"
      },
      "outputs": [],
      "source": [
        "prompts = [\n",
        "    \"The nature of reality is\",\n",
        "    \"Consciousness arises from\",\n",
        "    # TODO: Add 3 more philosophical prompts\n",
        "]\n",
        "\n",
        "# TODO: Generate 2 completions for each prompt\n",
        "# Use different temperatures (0.7 and 1.2) to see the difference\n",
        "# Expected outcome: Compare creative vs conservative completions\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1-hints"
      },
      "source": [
        "<details>\n",
        "<summary>üí° Hint 1</summary>\n",
        "Temperature controls randomness: lower = more focused\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>üí° Hint 2</summary>\n",
        "Use temperature parameter in generator()\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2-header"
      },
      "source": [
        "### C2. Translation\n",
        "Access philosophy across languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2-example"
      },
      "outputs": [],
      "source": [
        "# Load translator (English to German)\n",
        "translator = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\", device=device)\n",
        "\n",
        "# Minimal example\n",
        "text = \"I think therefore I am\"\n",
        "translation = translator(text)\n",
        "print(f\"English: {text}\")\n",
        "print(f\"German: {translation[0]['translation_text']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2-exercise-header"
      },
      "source": [
        "#### üéØ Exercise C2: Multilingual Philosophy\n",
        "**Objective**: Translate key philosophical terms and verify accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2-exercise"
      },
      "outputs": [],
      "source": [
        "philosophical_terms = [\n",
        "    \"being\",\n",
        "    \"existence\",\n",
        "    \"knowledge\",\n",
        "    # TODO: Add 5 more terms\n",
        "]\n",
        "\n",
        "# TODO: Create an English-German philosophical dictionary\n",
        "# For bonus: translate a famous quote and its context\n",
        "# Expected outcome: Dictionary of translations\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3-header"
      },
      "source": [
        "### C3. Text Generation - Chat Models\n",
        "\n",
        "‚úçÔ∏è What is Text Generation?\n",
        "\n",
        "- Interactive philosophical dialogue.\n",
        "- AI continues or creates text based on a prompt\n",
        "- Like having a writing assistant that knows many styles\n",
        "- Useful for: Brainstorming, exploring ideas, creating examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3-example"
      },
      "outputs": [],
      "source": [
        "# For chat models, we'll use the text generation pipeline with special formatting\n",
        "chatbot = pipeline(\"text-generation\", model=\"gpt2\", device=device)\n",
        "\n",
        "# Minimal example\n",
        "user_input = \"What is wisdom?\"\n",
        "response = chatbot(user_input, max_length=50, pad_token_id=50256)\n",
        "print(f\"Human: {user_input}\")\n",
        "print(f\"AI: {response[0]['generated_text'][len(user_input):].strip()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What is the meaning of life?\"\n",
        "response = chatbot(user_input, max_length=550, pad_token_id=50256)\n",
        "print(f\"Human: {user_input}\")\n",
        "print(f\"AI: {response[0]['generated_text'][len(user_input):].strip()}\")"
      ],
      "metadata": {
        "id": "p1XP09MTrz-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3-exercise-header"
      },
      "source": [
        "#### üéØ Exercise C3: Philosophical Dialogue\n",
        "**Objective**: Create a multi-turn philosophical conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3-exercise"
      },
      "outputs": [],
      "source": [
        "# TODO: Have a 4-turn conversation about a philosophical topic\n",
        "# Track the dialogue history\n",
        "# Evaluate if the AI stays on topic\n",
        "\n",
        "conversation_history = []\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4-header"
      },
      "source": [
        "### C4. Text-to-Image (Conceptual)\n",
        "\n",
        "üé® What is Text-to-Image?\n",
        "\n",
        "- Generate images from text descriptions\n",
        "- Visualize abstract concepts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4-example"
      },
      "outputs": [],
      "source": [
        "# Note: Full text-to-image models require ~4GB+ RAM\n",
        "# Here's how you would use one:\n",
        "\n",
        "print(\"üé® Text-to-Image Concept Demo\")\n",
        "print(\"\\nIf running a full model, you would:\")\n",
        "print(\"1. Load model: pipeline('text-to-image', model='runwayml/stable-diffusion-v1-5')\")\n",
        "print(\"2. Generate: image = generator('philosophical concept visualization')\")\n",
        "print(\"\\nExample prompts for philosophical visualization:\")\n",
        "\n",
        "prompts = [\n",
        "    \"The allegory of the cave by Plato, dramatic lighting\",\n",
        "    \"The trolley problem ethical dilemma, minimalist illustration\",\n",
        "    \"Zen Buddhism meditation, peaceful abstract art\",\n",
        "    # TODO: Add 2 more visualization ideas\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"- {prompt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "category-c-synthesis-header"
      },
      "source": [
        "### üîß Category C Synthesis\n",
        "**Objective**: Build a creative philosophy exploration tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "category-c-synthesis"
      },
      "outputs": [],
      "source": [
        "def philosophical_exploration(topic):\n",
        "    \"\"\"Use creative tools to explore a philosophical topic\"\"\"\n",
        "    # TODO: Given a topic, use C-category tools to:\n",
        "    # 1. Generate 3 different perspectives on it (C1)\n",
        "    # 2. Translate the key insight (C2)\n",
        "    # 3. Create a dialogue about it (C3)\n",
        "    # 4. Suggest a visual representation (C4)\n",
        "    pass\n",
        "\n",
        "# Test with a topic\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part5-header"
      },
      "source": [
        "## Part 5: Integration & Showcase (15 minutes)\n",
        "\n",
        "### üéØ Final Project: Your Research Assistant\n",
        "**Objective**: Combine capabilities from all categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final-project"
      },
      "outputs": [],
      "source": [
        "class PhilosophyResearchAssistant:\n",
        "    def __init__(self):\n",
        "        # TODO: Initialize 3-4 key pipelines you'll use\n",
        "        pass\n",
        "\n",
        "    def analyze_text(self, text):\n",
        "        \"\"\"Comprehensive text analysis using A-category tools\"\"\"\n",
        "        # TODO: Implement using A1, A2, A3\n",
        "        pass\n",
        "\n",
        "    def extract_insights(self, text):\n",
        "        \"\"\"Extract knowledge using B-category tools\"\"\"\n",
        "        # TODO: Implement using B1, B2, B3\n",
        "        pass\n",
        "\n",
        "    def explore_concept(self, concept):\n",
        "        \"\"\"Creative exploration using C-category tools\"\"\"\n",
        "        # TODO: Implement using C1, C2, C3\n",
        "        pass\n",
        "\n",
        "# Create and test your assistant\n",
        "assistant = PhilosophyResearchAssistant()\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "combination-matrix"
      },
      "source": [
        "## üéØ Capability Combination Matrix\n",
        "\n",
        "Which capabilities work well together?\n",
        "\n",
        "| Combination | Use Case |\n",
        "|---|---|\n",
        "| A1 + A2 | Sentiment analysis of texts about specific philosophers |\n",
        "| A3 + B1 | Classify text then ask targeted questions |\n",
        "| B2 + B3 | Summarize multiple texts and find similar themes |\n",
        "| A2 + C2 | Extract names and translate for international research |\n",
        "| B1 + C1 | Answer questions then generate follow-up ideas |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "module-summary"
      },
      "source": [
        "## üìä Lab Summary\n",
        "\n",
        "You've learned 10 fundamental LLM capabilities:\n",
        "- **Understanding** (A): Classification, NER, Zero-shot\n",
        "- **Knowledge** (B): Q&A, Summarization, Similarity\n",
        "- **Creating** (C): Generation, Translation, Chat, Images\n",
        "\n",
        "### üöÄ Next Lab Preview\n",
        "In Lab 8, we'll use these same capabilities with more powerful API-based models, learning:\n",
        "- How to access GPT-4, Claude, and other large models\n",
        "- Prompt engineering for better results\n",
        "- Cost management and when to use APIs vs local models\n",
        "\n",
        "### üè† Take-Home Challenge\n",
        "Pick one capability that interests you most and:\n",
        "1. Find a more specialized model on Hugging Face\n",
        "2. Apply it to your research area\n",
        "3. Document what worked and what didn't"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshooting"
      },
      "source": [
        "## üÜò Troubleshooting\n",
        "\n",
        "| Issue | Solution |\n",
        "|---|---|\n",
        "| Out of memory | Use smaller models or reduce batch size |\n",
        "| Slow performance | Enable GPU in Colab: Runtime ‚Üí Change runtime type |\n",
        "| Model not loading | Check internet connection and model name |\n",
        "| Poor results | Try different models from the same category |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTfzyODWpQh7"
      },
      "source": [
        "## Author:\n",
        "\n",
        "[Yunus Emre Tapan](https://www.linkedin.com/in/yemretapan/)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}